{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pf416e\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_new.csv')\n",
    "test = pd.read_csv('test_new.csv')\n",
    "\n",
    "org = pd.read_excel('Final_Train.xlsx')\n",
    "target=org.Fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.concat([train, test])\n",
    "\n",
    "##One hot encoding\n",
    "dfmerged = pd.concat([df_new[['Experience1','Rating1', 'Feedback1']],\n",
    "           pd.get_dummies(df_new['Profile'],drop_first = True),pd.get_dummies(df_new['Places'],drop_first = True),pd.get_dummies(df_new['City'],drop_first = True),pd.get_dummies(df_new['Miscellaneous_Info8'],drop_first = True),pd.get_dummies(df_new['Qualification8'],drop_first = True)],axis=1)\n",
    "\n",
    "dfmerged.columns = np.arange(len(dfmerged.columns))\n",
    "\n",
    "train1=dfmerged[:5961]\n",
    "test1=dfmerged[5961:7948]\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train1, target, train_size=0.7, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=200,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=99, silent=True,\n",
       "       subsample=0.85)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=xgb.XGBRegressor(colsample_bylevel=0.9, \n",
    "                       colsample_bytree=0.9,\n",
    "                       gamma=1, \n",
    "                       learning_rate=0.1, \n",
    "                       max_depth=10,\n",
    "                       min_child_weight=1, \n",
    "                       n_estimators=200, \n",
    "                       objective='reg:linear', \n",
    "                       reg_alpha=1, \n",
    "                       reg_lambda=1,\n",
    "                       scale_pos_weight=1, \n",
    "                       seed=99, \n",
    "                       subsample=0.85,\n",
    "                       silent=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6767294796091401\n",
      "0.2626712265799812\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model to file\n",
    "pickle.dump(model, open(\"basic_ohc.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model Loading\n",
    "xgb_ld = pickle.load(open(\"basic_ohc.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.2456155252583\n",
      "164.9629616980957\n"
     ]
    }
   ],
   "source": [
    "ypred = xgb_ld.predict(X_train)\n",
    "ypred_val = xgb_ld.predict(X_validation)\n",
    "\n",
    "\n",
    "print(sqrt(mean_squared_error(y_train, ypred)))\n",
    "print(sqrt(mean_squared_error(y_validation, ypred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**Data For Stacking**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "xgb_ld = pickle.load(open(\"basic_ohc.pickle.dat\", \"rb\"))\n",
    "\n",
    "y_all=xgb_ld.predict(train1)\n",
    "y_all=pd.DataFrame(y_all)\n",
    "\n",
    "y_all.columns=['xgb_wocat']\n",
    "\n",
    "y_all.to_csv('xgb_wocat_stck_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Without Adjustment\n",
    "y_pred_test2=xgb_ld.predict(test1)\n",
    "y_pred_test2=pd.DataFrame(y_pred_test2)\n",
    "y_pred_test2.columns=['Fee_pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**Validation Data For Stacking**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_ld = pickle.load(open(\"basic_ohc.pickle.dat\", \"rb\"))\n",
    "\n",
    "y_predicted_test=y_all=xgb_ld.predict(test1)\n",
    "y_predicted_test=pd.DataFrame(y_predicted_test)\n",
    "y_predicted_test.columns=['xgb_wocat']\n",
    "y_predicted_test.to_csv('xgb_wocat_stck_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#With Adjustment\n",
    "fee_test = pd.read_excel('Final_Test.xlsx')\n",
    "fee_test=fee_test['Miscellaneous_Info']\n",
    "fee_test1=pd.DataFrame(fee_test)\n",
    "\n",
    "for i in range(1987):\n",
    "    if (pd.isnull(fee_test1['Miscellaneous_Info'][i])==False):\n",
    "        myString=fee_test1['Miscellaneous_Info'][i]\n",
    "        t=myString.find('₹')\n",
    "        if (t>=0):\n",
    "            val=myString[t:t+7]\n",
    "            fee_test1.at[i,'fee_new_info']=val\n",
    "            \n",
    "fee_test1['fee_new_info'].fillna(0, inplace=True)\n",
    "fee_test1['fee_new_info']=fee_test1['fee_new_info'].str.replace('[^0-9]','')\n",
    "fee_test1['fee_new_info']=fee_test1['fee_new_info'].str.replace('[^\\w\\s]','')\n",
    "del fee_test1['Miscellaneous_Info']\n",
    "\n",
    "\n",
    "result2=pd.concat([y_pred_test2, fee_test1], axis=1)\n",
    "result2['fee_new_info'] = result2['fee_new_info'].str.strip()\n",
    "result2['fee_new_info']=pd.to_numeric(result2.fee_new_info)\n",
    "result2['fee_new_info'].fillna(0, inplace=True)\n",
    "\n",
    "result2['fee_new_info'] = np.where(result2['fee_new_info']>=1000,100,result2['fee_new_info'])\n",
    "result2['Fees']=np.where(result2['fee_new_info']==0,result2['Fee_pred'],result2['fee_new_info'])\n",
    "del result2['Fee_pred']\n",
    "del result2['fee_new_info']\n",
    "result2.to_csv('submission_ohc_xgb_withadj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chk1=pd.read_excel('Final_Test.xlsx')\n",
    "chk2=chk1['Qualification'].str.contains('inspired')\n",
    "chk2=pd.DataFrame(chk2)\n",
    "chk2['td']=np.where(chk2['Qualification']==True,100,0)\n",
    "del chk2['Qualification']\n",
    "\n",
    "result3=pd.concat([result2,chk2],axis=1)\n",
    "\n",
    "result3['Fees']=result3['Fees']+result3['td']\n",
    "del result3['td']\n",
    "\n",
    "result3.to_excel('submission_ohc_xgb_withadj_v1.xlsx', index=False)#0.74267647"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**XGBoost_Term_Document_Matrix**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('df_tf_idf_wc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(df_new.Miscellaneous_Info10)\n",
    "msc_df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "msc_df=pd.DataFrame(msc_df)\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(df_new.Qualification10)\n",
    "qual_df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "qual_df=pd.DataFrame(qual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new_v1=pd.concat([qual_df,msc_df], axis=1)\n",
    "df_new_v2=pd.concat([df_new,df_new_v1], axis=1)\n",
    "\n",
    "del df_new_v2['Qualification10']\n",
    "del df_new_v2['Miscellaneous_Info10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof1=pd.get_dummies(df_new_v2['Profile'],drop_first = True)\n",
    "plac1=pd.get_dummies(df_new_v2['Places'],drop_first = True)\n",
    "city1=pd.get_dummies(df_new_v2['City'],drop_first = True)\n",
    "\n",
    "dfmerged=pd.concat([df_new_v2,prof1,plac1,city1],axis=1)\n",
    "\n",
    "del dfmerged['Profile']\n",
    "del dfmerged['Places']\n",
    "del dfmerged['City']\n",
    "\n",
    "dfmerged.columns = np.arange(len(dfmerged.columns))\n",
    "\n",
    "train1=dfmerged[:5961]\n",
    "test1=dfmerged[5961:7948]\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train1, target, train_size=0.7, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
       "       colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=20, min_child_weight=2, missing=None, n_estimators=300,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=99, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tdm=xgb.XGBRegressor(colsample_bylevel=0.8, \n",
    "                       colsample_bytree=0.8,\n",
    "                       gamma=1, \n",
    "                       learning_rate=0.01, \n",
    "                       max_depth=20,\n",
    "                       min_child_weight=2, \n",
    "                       n_estimators=300, \n",
    "                       objective='reg:linear', \n",
    "                       reg_alpha=1, \n",
    "                       reg_lambda=1,\n",
    "                       scale_pos_weight=1, \n",
    "                       seed=99, \n",
    "                       subsample=0.8,\n",
    "                       silent=True)\n",
    "model_tdm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814211911779566\n",
      "0.25353176818447254\n"
     ]
    }
   ],
   "source": [
    "print(model_tdm.score(X_train, y_train))\n",
    "print(model_tdm.score(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model to file\n",
    "pickle.dump(model_tdm, open(\"basic_xgb_tdm.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model Loading\n",
    "xgb_tdm_ld = pickle.load(open(\"basic_xgb_tdm.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.45724582331675\n",
      "165.98220092806733\n"
     ]
    }
   ],
   "source": [
    "ypred = xgb_tdm_ld.predict(X_train)\n",
    "ypred_val = xgb_tdm_ld.predict(X_validation)\n",
    "\n",
    "\n",
    "print(sqrt(mean_squared_error(y_train, ypred)))\n",
    "print(sqrt(mean_squared_error(y_validation, ypred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**Data For Stacking**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_tdm_ld = pickle.load(open(\"basic_xgb_tdm.pickle.dat\", \"rb\"))\n",
    "\n",
    "\n",
    "y_all=xgb_tdm_ld.predict(train1)\n",
    "y_all=pd.DataFrame(y_all)\n",
    "\n",
    "y_all.columns=['xgb_tdm']\n",
    "\n",
    "y_all.to_csv('xgb_tdm_stck_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Without Adjustment\n",
    "y_pred_test2=xgb_tdm_ld.predict(test1)\n",
    "y_pred_test2=pd.DataFrame(y_pred_test2)\n",
    "y_pred_test2.columns=['Fee_pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**Validation Data For Stacking**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_tdm_ld = pickle.load(open(\"basic_xgb_tdm.pickle.dat\", \"rb\"))\n",
    "\n",
    "y_predicted_test=xgb_tdm_ld.predict(test1)\n",
    "y_predicted_test=pd.DataFrame(y_predicted_test)\n",
    "y_predicted_test.columns=['xgb_tdm']\n",
    "y_predicted_test.to_csv('xgb_tdm_stck_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#With Adjustment\n",
    "fee_test = pd.read_excel('Final_Test.xlsx')\n",
    "fee_test=fee_test['Miscellaneous_Info']\n",
    "fee_test1=pd.DataFrame(fee_test)\n",
    "\n",
    "for i in range(1987):\n",
    "    if (pd.isnull(fee_test1['Miscellaneous_Info'][i])==False):\n",
    "        myString=fee_test1['Miscellaneous_Info'][i]\n",
    "        t=myString.find('₹')\n",
    "        if (t>=0):\n",
    "            val=myString[t:t+7]\n",
    "            fee_test1.at[i,'fee_new_info']=val\n",
    "            \n",
    "fee_test1['fee_new_info'].fillna(0, inplace=True)\n",
    "fee_test1['fee_new_info']=fee_test1['fee_new_info'].str.replace('[^0-9]','')\n",
    "fee_test1['fee_new_info']=fee_test1['fee_new_info'].str.replace('[^\\w\\s]','')\n",
    "del fee_test1['Miscellaneous_Info']\n",
    "\n",
    "\n",
    "result2=pd.concat([y_pred_test2, fee_test1], axis=1)\n",
    "result2['fee_new_info'] = result2['fee_new_info'].str.strip()\n",
    "result2['fee_new_info']=pd.to_numeric(result2.fee_new_info)\n",
    "result2['fee_new_info'].fillna(0, inplace=True)\n",
    "\n",
    "result2['fee_new_info'] = np.where(result2['fee_new_info']>=1000,100,result2['fee_new_info'])\n",
    "result2['Fees']=np.where(result2['fee_new_info']==0,result2['Fee_pred'],result2['fee_new_info'])\n",
    "del result2['Fee_pred']\n",
    "del result2['fee_new_info']\n",
    "result2.to_csv('submission_tdm_xgb_withadj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk1=pd.read_excel('Final_Test.xlsx')\n",
    "chk2=chk1['Qualification'].str.contains('inspired')\n",
    "chk2=pd.DataFrame(chk2)\n",
    "chk2['td']=np.where(chk2['Qualification']==True,100,0)\n",
    "del chk2['Qualification']\n",
    "\n",
    "result3=pd.concat([result2,chk2],axis=1)\n",
    "\n",
    "result3['Fees1']=np.where(result3['td']==100,100,result3['Fees'])\n",
    "del result3['Fees']\n",
    "del result3['td']\n",
    "\n",
    "result3.columns=['Fees']\n",
    "\n",
    "result3.to_excel('submission_tdm_xgb_withadj_v1.xlsx', index=False)#0.74462449"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**TF_IDF**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('df_tf_idf_wc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pf416e\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df_new.Miscellaneous_Info10)\n",
    "msc_df1 = pd.DataFrame(x.toarray(), columns=v.get_feature_names())\n",
    "msc_df1=pd.DataFrame(msc_df1)\n",
    "\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df_new.Qualification10)\n",
    "qual_df1 = pd.DataFrame(x.toarray(), columns=v.get_feature_names())\n",
    "qual_df1=pd.DataFrame(qual_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new_v1=pd.concat([qual_df,msc_df], axis=1)\n",
    "df_new_v2=pd.concat([df_new,df_new_v1], axis=1)\n",
    "\n",
    "del df_new_v2['Qualification10']\n",
    "del df_new_v2['Miscellaneous_Info10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prof1=pd.get_dummies(df_new_v2['Profile'],drop_first = True)\n",
    "plac1=pd.get_dummies(df_new_v2['Places'],drop_first = True)\n",
    "city1=pd.get_dummies(df_new_v2['City'],drop_first = True)\n",
    "\n",
    "dfmerged=pd.concat([df_new_v2,prof1,plac1,city1],axis=1)\n",
    "\n",
    "del dfmerged['Profile']\n",
    "del dfmerged['Places']\n",
    "del dfmerged['City']\n",
    "\n",
    "dfmerged.columns = np.arange(len(dfmerged.columns))\n",
    "\n",
    "train1=dfmerged[:5961]\n",
    "test1=dfmerged[5961:7948]\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train1, target, train_size=0.7, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
       "       colsample_bytree=0.8, gamma=2, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=12, min_child_weight=4, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=99, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tfidf=xgb.XGBRegressor(colsample_bylevel=0.8, \n",
    "                       colsample_bytree=0.8,\n",
    "                       gamma=2, \n",
    "                       learning_rate=0.05, \n",
    "                       max_depth=12,\n",
    "                       min_child_weight=4, \n",
    "                       n_estimators=500, \n",
    "                       objective='reg:linear', \n",
    "                       reg_alpha=1, \n",
    "                       reg_lambda=1,\n",
    "                       scale_pos_weight=1, \n",
    "                       seed=99, \n",
    "                       subsample=0.8,\n",
    "                       silent=True)\n",
    "model_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7220599878947132\n",
      "0.24371649304521137\n"
     ]
    }
   ],
   "source": [
    "print(model_tfidf.score(X_train, y_train))\n",
    "print(model_tfidf.score(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model to file\n",
    "pickle.dump(model_tfidf, open(\"basic_xgb_tfidf.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model Loading\n",
    "xgb_tfidf_ld = pickle.load(open(\"basic_xgb_tfidf.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.36974001688573\n",
      "167.06988315194656\n"
     ]
    }
   ],
   "source": [
    "ypred = xgb_tfidf_ld.predict(X_train)\n",
    "ypred_val = xgb_tfidf_ld.predict(X_validation)\n",
    "\n",
    "\n",
    "print(sqrt(mean_squared_error(y_train, ypred)))\n",
    "print(sqrt(mean_squared_error(y_validation, ypred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**Data For Stacking**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_tfidf_ld = pickle.load(open(\"basic_xgb_tfidf.pickle.dat\", \"rb\"))\n",
    "\n",
    "y_all=xgb_tfidf_ld.predict(train1)\n",
    "y_all=pd.DataFrame(y_all)\n",
    "\n",
    "y_all.columns=['xgb_tf']\n",
    "\n",
    "y_all.to_csv('xgb_tf_stck_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Without Adjustment\n",
    "y_pred_test2=xgb_tfidf_ld.predict(test1)\n",
    "y_pred_test2=pd.DataFrame(y_pred_test2)\n",
    "y_pred_test2.columns=['Fee_pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h>**Validation Data For Stacking**</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_tfidf_ld = pickle.load(open(\"basic_xgb_tfidf.pickle.dat\", \"rb\"))\n",
    "\n",
    "y_predicted_test=xgb_tfidf_ld.predict(test1)\n",
    "y_predicted_test=pd.DataFrame(y_predicted_test)\n",
    "y_predicted_test.columns=['xgb_tf']\n",
    "y_predicted_test.to_csv('xgb_tf_stck_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#With Adjustment\n",
    "fee_test = pd.read_excel('Final_Test.xlsx')\n",
    "fee_test=fee_test['Miscellaneous_Info']\n",
    "fee_test1=pd.DataFrame(fee_test)\n",
    "\n",
    "for i in range(1987):\n",
    "    if (pd.isnull(fee_test1['Miscellaneous_Info'][i])==False):\n",
    "        myString=fee_test1['Miscellaneous_Info'][i]\n",
    "        t=myString.find('₹')\n",
    "        if (t>=0):\n",
    "            val=myString[t:t+7]\n",
    "            fee_test1.at[i,'fee_new_info']=val\n",
    "            \n",
    "fee_test1['fee_new_info'].fillna(0, inplace=True)\n",
    "fee_test1['fee_new_info']=fee_test1['fee_new_info'].str.replace('[^0-9]','')\n",
    "fee_test1['fee_new_info']=fee_test1['fee_new_info'].str.replace('[^\\w\\s]','')\n",
    "del fee_test1['Miscellaneous_Info']\n",
    "\n",
    "\n",
    "result2=pd.concat([y_pred_test2, fee_test1], axis=1)\n",
    "result2['fee_new_info'] = result2['fee_new_info'].str.strip()\n",
    "result2['fee_new_info']=pd.to_numeric(result2.fee_new_info)\n",
    "result2['fee_new_info'].fillna(0, inplace=True)\n",
    "\n",
    "result2['fee_new_info'] = np.where(result2['fee_new_info']>=1000,100,result2['fee_new_info'])\n",
    "result2['Fees']=np.where(result2['fee_new_info']==0,result2['Fee_pred'],result2['fee_new_info'])\n",
    "del result2['Fee_pred']\n",
    "del result2['fee_new_info']\n",
    "result2.to_csv('submission_tfidf_xgb_withadj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chk1=pd.read_excel('Final_Test.xlsx')\n",
    "chk2=chk1['Qualification'].str.contains('inspired')\n",
    "chk2=pd.DataFrame(chk2)\n",
    "chk2['td']=np.where(chk2['Qualification']==True,100,0)\n",
    "del chk2['Qualification']\n",
    "\n",
    "result3=pd.concat([result2,chk2],axis=1)\n",
    "\n",
    "result3['Fees']=result3['Fees']+result3['td']\n",
    "del result3['td']\n",
    "\n",
    "result3.to_excel('submission_tfidf_xgb_withadj_v1.xlsx', index=False) #0.73412535"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
